{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *P*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Albert Koppelmaa*\n",
    "* *Edouard Lacroix*\n",
    "* *Guillem Pruñonosa Soler*\n",
    "* *Gaëtan Schwartz*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = nx.read_adjlist(\"../data/components.graph\",create_using=nx.DiGraph)\n",
    "absorbing = nx.read_adjlist(\"../data/absorbing.graph\",create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSurferWithRestart(graph):\n",
    "    node = rd.sample(graph.nodes(),1)\n",
    "    count = [0]* len(graph.nodes())\n",
    "    n = 1000\n",
    "    i = 0\n",
    "    while(i<n):\n",
    "        i+=1\n",
    "        out_edges = list(graph.out_edges(node))\n",
    "        if(len(out_edges)==0):\n",
    "            node = rd.sample(graph.nodes(),1)[0]\n",
    "        else:\n",
    "            node = rd.sample(list(graph.out_edges(node)),1)[0][1]\n",
    "        count[int(node)]+= 1\n",
    "    total = sum(count)\n",
    "    return [float(i)/total for i in count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.288, 0.135, 0.289, 0.288]\n",
      "[0.138, 0.354, 0.149, 0.21, 0.149]\n"
     ]
    }
   ],
   "source": [
    "print(randomSurferWithRestart(components))\n",
    "print(randomSurferWithRestart(absorbing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the algorithm would run properly a major bug had to be taken care of in the case of the absorbing graph. This is  because the absorbing graph has a node that doesn't have any outgoing edges stopping the random surfing process. To resolve this I had the algorithm choose a new starting node uniformly at random. The second problem is with disconnected subgraphs as in the case of components. In that case the page ranking depends completely on what node we start as that will determine what nodes are accessible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSurferImproved(graph):\n",
    "    node = rd.sample(graph.nodes(),1)\n",
    "    count = [0]* len(graph.nodes())\n",
    "    n = 1000\n",
    "    i = 0\n",
    "    df = 0.15\n",
    "    while(i<n):\n",
    "        i+=1\n",
    "        if(rd.random()< df):\n",
    "            node= rd.sample(graph.nodes(),1)[0]\n",
    "        out_edges = list(graph.out_edges(node))\n",
    "        if(len(out_edges)==0):\n",
    "            node = rd.sample(graph.nodes(),1)[0]\n",
    "        else:\n",
    "            node = rd.sample(list(graph.out_edges(node)),1)[0][1]\n",
    "        count[int(node)]+= 1\n",
    "    total = sum(count)\n",
    "    return [float(i)/total for i in count]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.148, 0.145, 0.152, 0.071, 0.135, 0.063, 0.143, 0.143]\n",
      "[0.155, 0.359, 0.148, 0.219, 0.119]\n"
     ]
    }
   ],
   "source": [
    "print(randomSurferImproved(components))\n",
    "print(randomSurferImproved(absorbing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the page rank score makes intuitive sense, as linking to a web page shows a certain level of trust or \"vouching\" for another webpage. It therefore makes sense to rank webpages based on how many times you end up on that website from other sites. This is seen in our normalised scores too. For components, the node 5 has the worst score as only one node points to it but not only it. On the other hand the node 2 has the best score as not only do 2 nodes point to it but it also points to nodes that soon enough return to the node 2 (2->0->1->2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = nx.read_adjlist(\"../data/wikipedia.graph\", create_using=nx.DiGraph)\n",
    "wikiTitles = pd.read_csv(\"../data/wikipedia_titles.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructMatrix(graph):\n",
    "    node= None\n",
    "    theta = 0.99\n",
    "    n=1000\n",
    "    i=0\n",
    "    size = len(graph.nodes())\n",
    "    #construct H u,v\n",
    "    H = np.empty((size,size))\n",
    "    nodes_with_edges = set()\n",
    "    for edge in graph.edges():\n",
    "        H[int(edge[0]),int(edge[1])] = 1/graph.degree[edge[0]]\n",
    "        nodes_with_edges.add(edge[0])\n",
    "        nodes_with_edges.add(edge[1])\n",
    "    \n",
    "    for node in graph.nodes():\n",
    "        if(node not in nodes_with_edges):\n",
    "            H[int(node)][:] += 1/size\n",
    "    G = theta*H + (1-theta)*(np.ones((size,size))/size)\n",
    "    return G\n",
    "def solve(graph):\n",
    "    size =graph.shape[0]\n",
    "    sol = np.ones((size))/size\n",
    "    maxIter = 10000\n",
    "    iterN = 0\n",
    "    while(iterN< maxIter):\n",
    "        iterN+=1\n",
    "        solNew = graph @ sol\n",
    "        sol = solNew/np.linalg.norm(solNew, ord=2)\n",
    "    return sol\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = constructMatrix(wiki)\n",
    "sol = solve(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3015 3953 4082  865 4079 3066 1676 3480 4055 5489]\n",
      "[0.031449115154348985, 0.03174701196379255, 0.03189343920763847, 0.032513713246994196, 0.033602843332839506, 0.03449060733654383, 0.034880229667211084, 0.034903143783195784, 0.03654710633462896, 0.03660087217466944]\n",
      "['Least squares', 'Physical paradox', 'Portal:Physics', 'Bessel function', 'Portal:Mathematics', 'Linear regression', 'e (mathematical constant)', 'Monty Hall problem', 'Portal:Algebra', 'X Window System core protocol']\n"
     ]
    }
   ],
   "source": [
    "ids = np.argsort(sol)[-10:]\n",
    "values = [sol[i] for i in ids]\n",
    "names = [wikiTitles.values[i][1] for i in ids]\n",
    "print(ids)\n",
    "print(values)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 pages with the highest PageRank score are : 'Least squares', 'Physical paradox', 'Portal:Physics', 'Bessel function', 'Portal:Mathematics', 'Linear regression', 'e (mathematical constant)', 'Monty Hall problem', 'Portal:Algebra', 'X Window System core protocol'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
